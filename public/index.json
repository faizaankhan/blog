[{"categories":["Tech"],"content":"I show how to configure dynamoDB in dev environment and discuss some of the basic API functionality of DynamoDB in this post","date":"2020-09-12","objectID":"/post_2_dynamo/","tags":["AWS","Technical Articles","DynamoDB"],"title":"Configuring DynamoDB and basic operations for ruby apps","uri":"/post_2_dynamo/"},{"categories":["Tech"],"content":"Intro Hi, in this blog post I‚Äôm discussing some of the basic API functions which come in handy to use dynamoDB. These are all well documented on Amazon documentation as well as the library which might use to integrate with AWS, So why this post ? The reason for that is there‚Äôs a lot of options, and to help you with what you need in the beginning here I list my opinions and my suggested way of doing it. Remember working on a DynamoDB is almost a no-brainer when you got your basics clear. If you are a beginner and you know nothing about no SQL databases, I have a basic introduction post where I talk about most of the if‚Äôs and but‚Äôs you need to know and a simple guide on the concepts DynamoDB here. Here my choice of language is Ruby, but it‚Äôs an easy digest for any other as well. Note for rails users For rails users, DynamoDB is not the right choice for ORM in my opinion, but you might have a different one. If you are looking for using DynamoDB with your Active Record here‚Äôs the best you got with this gem called Dynamoid. If that‚Äôs not what you need Dynamo for this is the right place. ","date":"2020-09-12","objectID":"/post_2_dynamo/:1:0","tags":["AWS","Technical Articles","DynamoDB"],"title":"Configuring DynamoDB and basic operations for ruby apps","uri":"/post_2_dynamo/"},{"categories":["Tech"],"content":"Setting up a local development environment Download a locally executable DynamoDB application which you can use for development from aws Navigate to the folder and run java -Djava.library.path=./DynamoDBLocal_lib -jar DynamoDBLocal.jar -help, use any option, if you want to. I use the inMemory flag, to not persist data locally and let it run just on memory, and the sharedDB for storing all-region work at one place, good for saving on some system requirements. The flags are well described here java -Djava.library.path=./DynamoDBLocal_lib -jar DynamoDBLocal.jar -sharedDb -inMemory And Hurray, your local DB server is running. Quickly download awscli if you don‚Äôt have one. awscli provides you with the superpowers to communicate with AWS from command line :p. Linux Users: sudo apt install awscli Mac Users: brew install awscli (Add Homebrew if you don‚Äôt have it üôÇ Alternatively, take some time and read about cli here Now that we have aws-cli and dynamoDB client running on the local machine. We can go ahead and run a command. Let‚Äôs see what all tables exists, we expect the output should be empty. But Before that we need to configure AWS credentials, don‚Äôt worry we only need fake values for the local system to work. Run aws configure Add any fake string as shown in the image below, for access key id and access key secret. Set an AWS region, some examples include, us-west-2, ap-south-1. Set CLI response type to JSON, or whatever your choice is if you read the CLI documentation. We have a local instance set, credentials added for aws-cli, and now we should be able to make a call to our local dynamoDB. aws dynamodb list-tables --endpoint-url http://localhost:8000 aws configure example (Click to Expand)\" aws configure example (Click to Expand) That‚Äôs all for local setup and using API endpoints through CLI. You can update your credentials to real one, and not pass an endpoint URL in a general case, to use the AWS dynamoDB which is on the cloud. If due to some config issue it doesn‚Äôt fetch data from the table you want, you might need to pass an end-point URL, and for that you can follow the standard scheme for AWS service URLs. Aws service URL structure is: protocol://service-code.region-code.amazonaws.com. So for a dynamoDB table in us-west-2, we will have the endpoint as https://dynamodb.us-west-2.amazonaws.com. ","date":"2020-09-12","objectID":"/post_2_dynamo/:2:0","tags":["AWS","Technical Articles","DynamoDB"],"title":"Configuring DynamoDB and basic operations for ruby apps","uri":"/post_2_dynamo/"},{"categories":["Tech"],"content":"Setting up gems and client configs on any ruby application Here, I will show you how to configure your ruby app to use dynamoDB. Rails users can add specific classes and codes as per their choices in initializers and concerns etc. We will use the gem aws-sdk-dynamodb, so create a Gemfile, and add the latest one from RubyGems, and bundle. At the time of writing this I‚Äôm using gem 'aws-sdk-dynamodb', '~\u003e 1.0.0.rc7' # In Gemfile source 'https://rubygems.org' gem 'aws-sdk-dynamodb', '~\u003e 1.0.0.rc7' Now we will create an AWS dynamoDB client object, such that it can be used to perform the actions. In the most basic syntax this is as simple as calling new on Aws::DynamoDB::Client class with a region option passed. And if you are in an environment with a preset AWS config, it is all you need. def client @client ||= Aws::DynamoDB::Client.new(region: \"us-west-2\") end Ok, we can define the aws global configs for this app if required as below, assuming credentials struct is from the environment. And that should be good to go for using client. Aws.config.update( access_key_id: credentials.aws[:access_key_id], secret_access_key: credentials.aws[:secret_access_key], region: credentials.aws[:region] ) We can also pass, the config key-value pairs to the Aws::DynamoDB::Client class while initializing it, and that will also be good enough. Since through this post we will be using local dynamoDB, we only need to pass a region and our local endpoint URL. def client @client ||= Aws::DynamoDB::Client.new(region: 'us-west-2', endpoint: 'http://localhost:8000') end By now, we have added the required gem, and have a client object. This looks like the right time to create a table. So let‚Äôs go ahead and do that. ","date":"2020-09-12","objectID":"/post_2_dynamo/:3:0","tags":["AWS","Technical Articles","DynamoDB"],"title":"Configuring DynamoDB and basic operations for ruby apps","uri":"/post_2_dynamo/"},{"categories":["Tech"],"content":"Working with tables and records ","date":"2020-09-12","objectID":"/post_2_dynamo/:4:0","tags":["AWS","Technical Articles","DynamoDB"],"title":"Configuring DynamoDB and basic operations for ruby apps","uri":"/post_2_dynamo/"},{"categories":["Tech"],"content":"Creating a table I hope you have been through my last post on dynamoDB and you have already created a table using the AWS web console. Here we will be doing the same but from the SDK. In general, you can add these code in a rails task, or a ruby script and run it when you require to setup. Also, many tend to use the web console to create the tables and use them since it‚Äôs a one-time affair, but it is important for them who are adding it to an application and want to use for different environments etc. We will use create_table API endpoint. Here we need to understand a few basic options which we will be sending in params. table_name: Table name üôÇ key_schema: Key schema is an array of objects containing information about fields which you want as your primary key. attribute_name: It‚Äôs the field name for which you are setting a primary key attribute key_type: It defines the role of the key attribute set, Hash defines a partition key and range defines a sort key. attribute_definitions: Here we need to define the data type of the attributes we are setting in key schemas for the table and any indexes which other than our primary index too. The data types for the attributes are: S - the attribute is of type String N - the attribute is of type Number B - the attribute is of type Binary provisioned_throughput: provisioned throughput is about what kind of capacity you wish to have and will pay for. We don‚Äôt need to jump into understanding the exact need we have, AWS is tricky here and it‚Äôs a whole bunch of a subject. If you need to understand how the billing works for the provisioned system you can start with this. In very naive terms we can understand this as below: RCU: Read capacity unit represents a read request for an item of 4KB size in 1 second. WCU: Write capacity unit represents a write request for an item of 1KB size in 1 second. # main.rb require 'aws-sdk-dynamodb' def create_test_table params = { table_name: \"test-dev\", key_schema: [ { attribute_name: \"id\", key_type: \"HASH\" # Partition Key }, { attribute_name: \"submitted_at\", key_type: \"RANGE\" # Sort Key } ], attribute_definitions: [ { attribute_name: \"id\", attribute_type: \"S\" }, { attribute_name: \"submitted_at\", attribute_type: \"N\" } ], provisioned_throughput: { read_capacity_units: 1, write_capacity_units: 1 } } result = client.create_table(params) puts \"Status: \" + result.table_description.table_status rescue Aws::DynamoDB::Errors::ServiceError =\u003e e puts \"Unable to create table: #{e.message}\\n\" end def client @client ||= Aws::DynamoDB::Client.new(region: 'us-west-2', endpoint: 'http://localhost:8000') end create_test_table After running the above code, you should be able to see your table listed using the call we made earlier. aws dynamodb list-tables --endpoint-url http://localhost:8000 creating a table example\" creating a table example ","date":"2020-09-12","objectID":"/post_2_dynamo/:4:1","tags":["AWS","Technical Articles","DynamoDB"],"title":"Configuring DynamoDB and basic operations for ruby apps","uri":"/post_2_dynamo/"},{"categories":["Tech"],"content":"Updating a table We can not update a table‚Äôs primary keys, but we can add global indexes with table update calls, update rcu, wcu, and perform other updates like enabling time_to_live. Yes, I am taking this opportunity to tell you something about time to live. Dynamo provides us with an option to set time to live for all the records we create in epoch(a kind of time format). Time to live is a great tool for apps that are storing data on dynamo temporarily. You can set it ttl (time_to_live) to given date time and the record will be deleted by dynamo when the time comes. For updates aws provides update_table, which can be used for updating rcu, wcu and adding GSI (global secondary index). Here I will use anothe api method update_time_to_live. Here, I am enabling time to live specification and also setting the attribute name, which will allow us to add a epoch value for the records time to live. def update_table result = client.update_time_to_live( { table_name: 'test-dev', time_to_live_specification: { enabled: true, attribute_name: \"ttl\" } } ) if result.time_to_live_specification.enabled puts \"TTL enabled\" end rescue Aws::DynamoDB::Errors::ServiceError =\u003e e puts e.message.to_s end ","date":"2020-09-12","objectID":"/post_2_dynamo/:4:2","tags":["AWS","Technical Articles","DynamoDB"],"title":"Configuring DynamoDB and basic operations for ruby apps","uri":"/post_2_dynamo/"},{"categories":["Tech"],"content":"Writing records on the table Writing records on the table is yet another simple task, you can use the below code and pass your record to add. What we are doing below is, we are calling put_item method with item and table name. Item consists of an object which can be multiple levels nested or flat, but must have the primary key attributes defined. As you already know, we can try new attributes on the fly and we only need to stick with the primary key attributes, others are all dynamically created. put_item will add an item or replace the item if there‚Äôs a primary key conflict. def create_record(item) client.put_item( table_name: 'test-dev', return_consumed_capacity: \"TOTAL\", item: item ) rescue Aws::DynamoDB::Errors::ServiceError =\u003e e puts e.message.to_s end create_record({ id: 12, submitted_at: 12-10-2020, name: 'John Doe', degree: 'BE' }) ","date":"2020-09-12","objectID":"/post_2_dynamo/:4:3","tags":["AWS","Technical Articles","DynamoDB"],"title":"Configuring DynamoDB and basic operations for ruby apps","uri":"/post_2_dynamo/"},{"categories":["Tech"],"content":"Fetching records from the table We can fetch a record by calling get_item, and we need to pass the primary key attributes (Both partition and sort key if both are created, or just partition key if there‚Äôs only one primary key attribute). Let‚Äôs use the get_item method and fetch the data we created just now. def fetch_record(key) response = client.get_item(table_name: 'test-dev', key: key) response.item rescue Aws::DynamoDB::Errors::ServiceError =\u003e e puts e.message end fetch_record({ id: 12, submitted_at: 12-10-2020}) ","date":"2020-09-12","objectID":"/post_2_dynamo/:4:4","tags":["AWS","Technical Articles","DynamoDB"],"title":"Configuring DynamoDB and basic operations for ruby apps","uri":"/post_2_dynamo/"},{"categories":["Tech"],"content":"Updating a record on the table We can use put_item and replace the entire record, or we can also just update a non-primary key attribute. Here we need to use expressions to make the update call using update_item. DynamoDB provides us with some expressions like an SQL syntax we use, one of which is used here and is set field = :the_variable_which_we_will_use_in_expression_attr_values. In update_expression we are passing a string that resembles a query to let dynamo identify a field with a specific name, which we will use in the expression_attribute_values to set a value. In return_values option we are setting UPDATED_NEW to get back the updated data. def update_record(key, field, new_value) client.update_item({ table_name: 'test-dev', key: key, update_expression: \"set #{field}= :field\", expression_attribute_values: { ':field' =\u003e new_value }, return_values: 'UPDATED_NEW' }) rescue Aws::DynamoDB::Errors::ServiceError =\u003e e puts e.message end ","date":"2020-09-12","objectID":"/post_2_dynamo/:4:5","tags":["AWS","Technical Articles","DynamoDB"],"title":"Configuring DynamoDB and basic operations for ruby apps","uri":"/post_2_dynamo/"},{"categories":["Tech"],"content":"Deleting a Table Just to finish-up. Delete is as simple as expected. def delete_table client.delete_table({ table_name: 'test-dev' }) puts \"Table deletion process started, aws will delete it soon\" rescue Aws::DynamoDB::Errors::ServiceError =\u003e e puts \"Unable to delete table: #{e.message}\\n\" end ","date":"2020-09-12","objectID":"/post_2_dynamo/:4:6","tags":["AWS","Technical Articles","DynamoDB"],"title":"Configuring DynamoDB and basic operations for ruby apps","uri":"/post_2_dynamo/"},{"categories":["Tech"],"content":"Some other APIs to look at In the last section we saw some basic scaffolding for executing simple calls to dynamoDB. It can be of good use, and other than that we also have few other important APIs to look at. I will just describe them, and you can have a brief understanding of them, such that you know what to use, when you need it. Batch APIs BatchGetItem: It can be used to fetch items from different tables using Partition Key and Sort Key. In a single BatchGetItem call, we can fetch up to 16MB data or 100 items. BatchWriteItem: It can be used to delete or put items on one or more tables in DynamoDB in one call. We can write up to 16 MB data, which can be 25 put and delete requests. Query and Pagination APIs Query: Query operation will return all items that are matched with the partition key of the table. Sort Key is further useful to filter and sort items but it is optional. Scan: Scan operation doesn‚Äôt require Partition Key or Sort Key to fetch results from the table. As the name suggests, it scans an entire table to filter results based on attribute values passed as filters. Pagination: DynamoDB Query/Scan results return a maximum of 1MB response size so if our request matches an item of size more than 1MB, it gets automatically divided into pages. In such cases DynamoDB returns a special response parameter ‚ÄúLastEvaluatedKey‚Äù and this can be used to fetch next page results. Please note we need to pass the value of ‚ÄúLastEvaluatedKey‚Äù as ‚ÄúExclusiveStartKey‚Äù in the next request to DynamoDB. ","date":"2020-09-12","objectID":"/post_2_dynamo/:5:0","tags":["AWS","Technical Articles","DynamoDB"],"title":"Configuring DynamoDB and basic operations for ruby apps","uri":"/post_2_dynamo/"},{"categories":["Tech"],"content":"Secondary Indexes DynamoDB is very bad with fetching data when you are not using a key to get the data, and instead doing a scan operation. It was not meant to do that ever, if you need search capabilities elastic search is your goto option. We can query on primary indexes and can get data, but when we know that we will be needing some other attributes pairs too for some data fetching we can go ahead, and add them as indexes. Dynamo provides us with two types of secondary indexes. Global secondary index ‚Äì An index with a partition key and sort key that can be different from those on the table. They are stored detached from the main table with their own partition. Local secondary index ‚Äì An index that has the same partition key as the table, but a different sort key. They are stored with the table, in the same partition as the data it is referencing to. ","date":"2020-09-12","objectID":"/post_2_dynamo/:6:0","tags":["AWS","Technical Articles","DynamoDB"],"title":"Configuring DynamoDB and basic operations for ruby apps","uri":"/post_2_dynamo/"},{"categories":["Tech"],"content":"End words You can start working now, you have enough knowledge about the tools and and it‚Äôs always the journey where you learn, I hope I was able to stick to the very basics and help you out in understanding them. Adios. ","date":"2020-09-12","objectID":"/post_2_dynamo/:7:0","tags":["AWS","Technical Articles","DynamoDB"],"title":"Configuring DynamoDB and basic operations for ruby apps","uri":"/post_2_dynamo/"},{"categories":["Tech"],"content":"I discuss the bare minimum concepts one needs to start working with DynamoDB, or to select DynamoDB for their application","date":"2020-08-30","objectID":"/post_1_dynamo/","tags":["AWS","Technical Articles","DynamoDB"],"title":"Bare minimum approach on learning AWS DynamoDB","uri":"/post_1_dynamo/"},{"categories":["Tech"],"content":"Why this post ? I am working with DynamoDB for some time now and on that journey I have explored about things that I would like to share. I am no master at Dynamo and nor does one needs to be for being able to utilize it‚Äôs capacity. Here are most of the bare minimum things you need to know before jumping into starting to integrate DynamoDB to your application or before you chose it as a viable option. The post is pretty basic, and you can skip topics if you are well aware of them. ","date":"2020-08-30","objectID":"/post_1_dynamo/:1:0","tags":["AWS","Technical Articles","DynamoDB"],"title":"Bare minimum approach on learning AWS DynamoDB","uri":"/post_1_dynamo/"},{"categories":["Tech"],"content":"What‚Äôs a NoSQL aka Not Only SQL Database System ? A NoSQL database provides you with the flexibility in managing data where you ideally don‚Äôt need to stick to a predefined schema for tabular storage. While NoSQL databases have stayed with us for a long time now, they became a thing in the era of cloud, big data, and high volume web and mobile applications. NoSQL databases are generally linked to: High Scalability High Availability Big Data Storage Capacity Easy Replication Fast Performance The above points sound so cool, but it‚Äôs not entirely true for all the NoSQL databases and there are many more variables and architectural choices made which provides you with them. One mantra for NoSQL which I remind myself whenever I am switching from a relational system is, NoSQL is a denormalized system and I must not think of the DB structure in a relational system. Try to flatten the data, and don‚Äôt worry much if there‚Äôs a few data duplication. Like you don‚Äôt go ahead and make a table to store schools when a student table is linked with a school. ","date":"2020-08-30","objectID":"/post_1_dynamo/:2:0","tags":["AWS","Technical Articles","DynamoDB"],"title":"Bare minimum approach on learning AWS DynamoDB","uri":"/post_1_dynamo/"},{"categories":["Tech"],"content":"Some of the common categories of NoSQL databases Key-Value Store: They are essentially big hash tables of keys and values( Common examples are Dynamo DB and Redis). Document-based Store: The documents are made up of tagged elements(Common examples include MongoDB and CouchDB). Column-Based Store: They have storage blocks and each storage block contains data from only one column(HBase, Cassandra) Graph-Based Store: They are network-based, and uses edges and nodes to store/represent data(SAP Hana, Neo4J) I know that‚Äôs pretty boring stuff when you just read it, so I would advise to go ahead and see some of the data examples, of how they are stored and everything, will be clearer. An Example of Data stored in a Key-Value Store: { \"CarType\": \"Sedan\", \"Name\": \"Maserati Ghibli\", \"Price\": \"$10,000\" \u003c..other attributes\u003e }, { \"CarType\": \"Hatchback\", \"Name\": \"Volkswagon Polo\", \"Price\": \"$5,000\" \u003c..other attributes\u003e } ","date":"2020-08-30","objectID":"/post_1_dynamo/:3:0","tags":["AWS","Technical Articles","DynamoDB"],"title":"Bare minimum approach on learning AWS DynamoDB","uri":"/post_1_dynamo/"},{"categories":["Tech"],"content":"How to select the right DB to use ? Though we already have a selection of DynamoDB in this post here, it‚Äôs of great importance that you know what you are using and why. What comes in handy for choosing what you need is the popular CAP theorem by Eric Brewer for distributed systems. Since NoSQL databases are in generally largely distributed systems, people have used it in the selection of their NoSQL DB. Coming to the theorem, it states that a networked shared data systems can only guarantee/strongly support two of the following three properties: Consistency ‚Äî A guarantee that every node in a distributed cluster returns the same, most recent, successful write. Availability ‚Äî Every non-failing node returns a response for all read and write requests in a reasonable amount of time. Partition Tolerant ‚Äî The system continues to function and upholds its consistency guarantees in spite of network partitions. Here‚Äôs an image which is a nice depiction of the above 3 properties. You can see that, DynamoDB provides us with Availability and Partition Tolerance, but doesn‚Äôt guarantee Consistency. Although as of 2020 AWS has a strongly consistent and transactional consistent model, where AWS promises data consistency, it‚Äôs not the best player in that area. CAP Theorem (Click to Expand)\" CAP Theorem (Click to Expand) ","date":"2020-08-30","objectID":"/post_1_dynamo/:4:0","tags":["AWS","Technical Articles","DynamoDB"],"title":"Bare minimum approach on learning AWS DynamoDB","uri":"/post_1_dynamo/"},{"categories":["Tech"],"content":"Are you still unsure ? Here‚Äôs a list of questions, I copied from AWS documentation üòâ These are just enough to decide if all the ‚ÄúGyaan‚Äù above didn‚Äôt work. Can you organize your data in hierarchies or an aggregate structure in one or two tables? Are traditional backups impractical because of table update rate or overall data size? Does your database workload vary significantly by time or have high-traffic events? Does your application or service consistently require response time in the single milliseconds? Do you need to provide services in a scalable, replicated configuration? Does your application need to store data in the high-terabyte size range? Are you willing to invest in a short but possibly steep NoSQL learning curve? Is data protection important? Those questions are really the marketing ones. But hey, AWS promises you something. I will add another one: Are you on AWS cloud services already? You can obviously use it from other services like a GCP, but that won‚Äôt be secure on the go. ","date":"2020-08-30","objectID":"/post_1_dynamo/:5:0","tags":["AWS","Technical Articles","DynamoDB"],"title":"Bare minimum approach on learning AWS DynamoDB","uri":"/post_1_dynamo/"},{"categories":["Tech"],"content":"Introducing the already introduced DynamoDB Amazon DynamoDB is a key-value based NoSQL database which is highly scalable, reliable, fully managed and durable database with built-in security, backup and restore, and in-memory caching for internet-scale applications By fully managed they mean, you don‚Äôt need to worry about the underlying hardware, servers, or operating system. Data stored in the DynamoDB is redundantly copied across multiple Availability Zones and thus it protects data loss due to underlying hardware failures by default, which is a big thing. In simple terms, you can say that DynamoDB can handle a large amount of data and large traffic without you worrying about the architecture behind, and can be integrated to your application like butter with the AWS ecosystem. An example usage of DynamoDB in the AWS Ecosystem\" An example usage of DynamoDB in the AWS Ecosystem ","date":"2020-08-30","objectID":"/post_1_dynamo/:6:0","tags":["AWS","Technical Articles","DynamoDB"],"title":"Bare minimum approach on learning AWS DynamoDB","uri":"/post_1_dynamo/"},{"categories":["Tech"],"content":"Data Organisation and Modelling DynamoDB organizes data as tables, yes tables. Each table contains several items in each row, and each item has keys and values for each column. UUID (Primary Key) StudentName MathsScore BioScore AccountsScore 1212-3322-5861-9865 Ram 59 98 1582-2249-9513-6538 Shyam 79 89 In the example above, one item can be represented in JSON data as: { \"UUID\": 1212-3322-5861-9865, \"StudentName\": 'Ram', \"MathsScore\": 59, \"BioScore\": 98 } What‚Äôs different about a DynamoDB table is that you have the freedom to select a primary key while keeping all other columns dynamic. So in the above example, you can keeping adding different kinds of scores or any other information. You just define the primary key and data can be added with a dynamic set of keys and values. ","date":"2020-08-30","objectID":"/post_1_dynamo/:7:0","tags":["AWS","Technical Articles","DynamoDB"],"title":"Bare minimum approach on learning AWS DynamoDB","uri":"/post_1_dynamo/"},{"categories":["Tech"],"content":"Primary Keys When you create a table in DynamoDB, in addition to the table name, you must specify the primary key of the table. The primary key uniquely identifies each item in the table, so that no two items can have the same key. A dynamo primary key is either based on a single field or a couple of fields. Partition key ‚Äì A simple primary key, composed of one attribute known as the partition key. DynamoDB uses the partition key‚Äôs value as input to an internal hash function. The output from the hash function determines the partition (physical storage internal to DynamoDB) in which the item will be stored. Partition key and sort key - Referred to as a composite primary key, and as the name suggests it is composed of two attributes. The first attribute is the partition key, and the second attribute is the sort key. All items with the same partition key value are stored together, in sorted order by sort key value. Let‚Äôs add a sort key on the previous example: UUID (Partition Key) StudentName (Sort Key) MathsScore BioScore AccountsScore 1212-3322-5861-9865 Ram 59 98 1582-2249-9513-6538 Shyam 79 89 When you have a composite primary key, the uniqueness is checked on the pair of partition and sort keys, so in the above example we have UUID, but uniqueness is only checked on UUID and StudentName together as a unit, so one can also store another record with the same UUID and a different StudentName. The selection of a wise primary key is very important as the DB is indexed on your primary key and provides with a quick result when you try to find by an indexed field. And this selection is one of the places where your most of the thinking should go when you are modeling your data. ","date":"2020-08-30","objectID":"/post_1_dynamo/:7:1","tags":["AWS","Technical Articles","DynamoDB"],"title":"Bare minimum approach on learning AWS DynamoDB","uri":"/post_1_dynamo/"},{"categories":["Tech"],"content":"Data types supported are: Scalar Types : Number, String, Binary, Boolean and Null. Document Types : List and Map Set Types : Number Set, String Set, and Binary Set. You don‚Äôt need to define them while creating any item, it‚Äôs just for a reference on what data types can be stored. ","date":"2020-08-30","objectID":"/post_1_dynamo/:7:2","tags":["AWS","Technical Articles","DynamoDB"],"title":"Bare minimum approach on learning AWS DynamoDB","uri":"/post_1_dynamo/"},{"categories":["Tech"],"content":"Creating a table in AWS Console Visit the AWS console page. Select DynamoDB from the services menu and click on the create table option. You have a small form, asking for the table name and primary key. Use the defaut options for now and click on create Table button. When you are creating a table you can provide partition key and an optional sort key, an important point to note is that these columns can‚Äôt be changed. You can update the attributes of any item in dynamo, but can never update a key if you ever want to, what you do is you delete the item and then re-create another one with a different key. Creating a table in DynamoDB\" Creating a table in DynamoDB You will see a screen like below Existing table view\" Existing table view Visit the items tab, there‚Äôs no item there, you will be using AWS API endpoints to fetch,create, update, delete items from your app but for now just go ahead and create your first item by clicking on Create Item üòÑ Existing table view\" Existing table view You can see how you can add other dynamic sets of keys and add their values on the go. Keep exploring the console options and you will get some hold on what it is. ","date":"2020-08-30","objectID":"/post_1_dynamo/:8:0","tags":["AWS","Technical Articles","DynamoDB"],"title":"Bare minimum approach on learning AWS DynamoDB","uri":"/post_1_dynamo/"},{"categories":["Tech"],"content":"How to get started ? Checkout AWS SDK for DynamoDB which is supported for several languages, and can be used to interact with DynamoDB API endpoints for basic DB operations seamlessly. You can also read my next post which will be more about the usage part of it. ","date":"2020-08-30","objectID":"/post_1_dynamo/:9:0","tags":["AWS","Technical Articles","DynamoDB"],"title":"Bare minimum approach on learning AWS DynamoDB","uri":"/post_1_dynamo/"},{"categories":["Tech"],"content":"Last words until the next one DynamoDB is one of the easiest no-sql databases to start working with, but as you keep exploring you can dive deeper into understanding its capabilities. In a follow-up article, I will be writing about indexes, read and write capacity units, API functions, and I will give a walkthrough on how you can use AWS APIs to create and manage a DyanmoDB table and show some CRUD operations. ","date":"2020-08-30","objectID":"/post_1_dynamo/:10:0","tags":["AWS","Technical Articles","DynamoDB"],"title":"Bare minimum approach on learning AWS DynamoDB","uri":"/post_1_dynamo/"},{"categories":["Tech"],"content":"References Here are a few links this article takes inspiration from. https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Introduction.html (AWS ecosystem example image) https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.CoreComponents.html https://medium.com/tensult/core-concepts-of-amazon-dynamodb-a265a3fc70a https://opensourceforu.com/2017/05/different-types-nosql-databases/ https://www.3pillarglobal.com/insights/exploring-the-different-types-of-nosql-databases https://www.mysoftkey.com/architecture/understanding-of-cap-theorem/ (CAP Theorem Diagram) https://www.geeksforgeeks.org/introduction-to-nosql/ ","date":"2020-08-30","objectID":"/post_1_dynamo/:11:0","tags":["AWS","Technical Articles","DynamoDB"],"title":"Bare minimum approach on learning AWS DynamoDB","uri":"/post_1_dynamo/"},{"categories":["personal"],"content":"Initial blogpost.","date":"2020-08-16","objectID":"/new_post/","tags":["personal"],"title":"First Ever Blog Post","uri":"/new_post/"},{"categories":["personal"],"content":"First Ever Blog Post Stepping into the writer‚Äôs world. Hi random visitor, you are either one of my friends I have forced to visit this place or someone who liked some work by the future me or maybe just the web crawler. In my pursuit of learning and trying out things, with my baby turtle steps, I have realized one thing, that feeling confident about something and being confident enough to explain other people are two very different things. Just like living a moment and being able to share other people how you felt about it. The later provides me with extreme joy and maybe as a human acceptance from people makes me happy about it. In general, I am no good with conversations, or writing, but it‚Äôs never too late right? So here‚Äôs me starting to share the experiences I have with creating something, configuring something, hating something, and living something. Wish me luck, and less procrastination. ","date":"2020-08-16","objectID":"/new_post/:0:0","tags":["personal"],"title":"First Ever Blog Post","uri":"/new_post/"},{"categories":null,"content":" Soemone who loves positive people. Aims to work with people having a lot of zeal and enthusiasm. Is always ready to learn new things and apply them. ","date":"2020-08-16","objectID":"/about/:0:0","tags":null,"title":"About Me","uri":"/about/"}]